{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:3px solid coral\"></hr>\n",
    "\n",
    "# Introduction to MPI\n",
    "\n",
    "<hr style=\"border:3px solid coral\"></hr>\n",
    "\n",
    "\n",
    "**MPI** (Message Passing Interface) is one of many libraries available for distributed memory computing.  Its main use is in High Performance Computing (HPC) and is widely used by computational scientists who want the benefit of multiprocessing on a computer cluster or super computer. \n",
    "\n",
    "We can use MPI on personal laptops as well to take advantage of multiple cores available on our own computers for improved performance. \n",
    "\n",
    "There are several implementations of the MPI standard.   Two main implementations are MPICH and OpenMPI.   Either one should work for what we will do here.  \n",
    "\n",
    "\n",
    "* [Demo 0](#demo0) (Almost) the simplest MPI example.\n",
    "\n",
    "* [Demo 1](#demo1) Pass a string message between processors. \n",
    "\n",
    "* [Demo 2](#demo2) Pass a scalar data between processors \n",
    "\n",
    "* [Demo 3](#demo3) Pass an array between processors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from matplotlib.pyplot import *\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo0\"></a>\n",
    "\n",
    "<hr style=\"border:2px solid coral\"></hr>\n",
    "\n",
    "## (Almost) the simplest MPI code\n",
    "\n",
    "<hr style=\"border:2px solid coral\"></hr>\n",
    "\n",
    "This example illustrates how to initialize and finalize the MPI library.  In this example, we also print out the rank of each processor. \n",
    "\n",
    "The basic requirement to use MPI are to include the `mpi.h` header file.  Then to compile, we have to use the `mpicc` rather than `gcc`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mpi_demo_01.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "void main(int argc, char** argv)\n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "    \n",
    "    int my_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "\n",
    "    printf(\"Rank %d\\n\",my_rank);\n",
    "\n",
    "    MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components \n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "    #include <stdio.h>\n",
    "    #include <mpi.h>\n",
    "\n",
    "We include the header file for the `printf` statement (`<stdio.h>`) and for MPI libraries that we want to reference. \n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "\n",
    "    void main(int argc, char** argv)\n",
    "    {\n",
    "        MPI_Init(&argc, &argv);\n",
    "        \n",
    "All MPI programs must initialized with input arguments. The reason will be come clear below, but this is how the MPI library will get access to our runtime environment. \n",
    "\n",
    "**Note:** All MPI library routines start with `MPI_`.  \n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "    int my_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "    \n",
    "The cores or \"processes\" that we launch are referenced by \"rank\".  If we launch $P$ processes, ranks $0,1,2,\\dots,P-1$ will be the value assigned to each process.  \"Rank\" is the number assigned by MPI to each process. \n",
    "\n",
    "This \"main\" program we are running is each a separate process, and so will have a unique \"rank\" identifier.   \n",
    "\n",
    "By passing the integer value `my_rank` by reference (using `&my_rank`), the MPI library routine `MPI_Comm_rank` can copy the rank value to the memory location referenced by `&my_rank`.  \n",
    "\n",
    "MPI_COMM_WORLD refers to the pool of processors we are using.  \n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "\n",
    "    printf(\"Rank %d\\n\",my_rank);\n",
    "    \n",
    "We print the value of the current rank that is running. \n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "\n",
    "        MPI_Finalize();\n",
    "    }\n",
    "    \n",
    "This statement should be the last statement in any MPI code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling an MPI code\n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "Because MPI is an external library, we need to be sure to \"link\" to the library when compiling our code.  MPI implementations provide convenient \"shell scripts\" that locate the libraries and provide necesary compiler flags to link in the MPI object files. \n",
    "\n",
    "For codes written in C, we can use `mpicc`.   For our purposes, we will just replace `gcc` with `mpicc`\n",
    "\n",
    "    mpicc -o mpi_demo_01 mpi_demo_01.c\n",
    "\n",
    "**Note:** Different implementations may have slightly different names for these shell scripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm -rf mpi_demo_01\n",
    "\n",
    "mpicc -o mpi_demo_01 mpi_demo_01.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running an MPI code\n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "To run an MPI code, we have to tell the executable how many processors to run our code on.   Our \"main\" program than becomes a \"target\" for each process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mpirun -n 4 mpi_demo_01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to Python Multiprocessing\n",
    "\n",
    "* When running an MPI code, our \"target\" process is our main program. Copies of this program will be run on each process.  It is up to the program to decide what to do. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo1\"></a>\n",
    "\n",
    "<hr style=\"border:2px solid coral\"></hr>\n",
    "\n",
    "##  Pass a message between processors\n",
    "\n",
    "<hr style=\"border:2px solid coral\"></hr>\n",
    "\n",
    "In this example, rank 0 will send a message to rank 1.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mpi_demo_02.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "#include <string.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "void main(int argc, char** argv)\n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int my_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &my_rank);\n",
    "    \n",
    "    if (my_rank == 0)\n",
    "    {\n",
    "        char msg[100] = \"Greetings from processor 0!\";\n",
    "        \n",
    "        int dest = 1;\n",
    "        int tag = 0;\n",
    "        int len = strlen(msg)+1;\n",
    "        MPI_Send(msg,len,MPI_CHAR,dest,tag,MPI_COMM_WORLD);\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        MPI_Status status;\n",
    "        int sender = 0;\n",
    "        int tag = 0;\n",
    "        char msg[100];\n",
    "        MPI_Recv(msg,100,MPI_CHAR,sender,tag,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n",
    "        printf(\"Rank %d received message : \\\"%s\\\"\\n\",my_rank,msg);\n",
    "    }\n",
    "    \n",
    "    MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components \n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "    if (my_rank == 0)\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        ....\n",
    "    }\n",
    "    \n",
    "In MPI, the rank identifier is commonly used to decide how a process should behave.  For example, the rank identifier is used to decide which part of an array to work on, which data file to read, and so on.  It is also common that \"rank 0\" is designated a special role.  For example, rank 0 often is the rank that reports to the console. \n",
    "\n",
    "In this example, we have designated \"rank 0\" to be the \"sender\" and \"rank 1\" to be the receiver.  \n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "    if (my_rank == 0)\n",
    "    {\n",
    "        char msg[100] = \"Greetings from processor 0!\";\n",
    "        ....\n",
    "    }\n",
    "\n",
    "\n",
    "A key difference between Python and MPI is that we have to be very specific about what exactly we are sending.  \n",
    "\n",
    "The \"message\" to be sent is an array of characters.  \n",
    "\n",
    "\n",
    "\n",
    "<hr style=\"border:1px solid black\"></hr>\n",
    "\n",
    "        int dest = 1;\n",
    "        int tag = 0;\n",
    "        int len  = strlen(msg) + 1;\n",
    "        MPI_Send(msg,len,MPI_CHAR,dest,tag,MPI_COMM_WORLD);\n",
    "\n",
    "This is the actual \"send\" command in MPI.   The arguments are : \n",
    "\n",
    "* **msg** : The message to be sent.  We use the term \"message\" generically to mean any string of bytes and so can mean character data or numeric data. \n",
    "\n",
    "\n",
    "* **len** : Length of the message to send, in units of the data type being sent. For character data, we include the end-of-line (EOL) character. \n",
    "\n",
    "\n",
    "* **MPI_CHAR** : Indicates the data type to send (character in this case).  This is needed to determine how many bytes are in the message.  \n",
    "\n",
    "\n",
    "* **dest** : The rank of the process that should receive the message. In this case, we send our message to \"rank 1\". \n",
    "\n",
    "\n",
    "* **tag** : Can be used to \"tag\" the message, in case several messages are sent to the same process.  \n",
    "\n",
    "\n",
    "* **MPI_COMM_WORLD** : The \"pool\" of processors we are working in.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the code\n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "We will run the code on two processors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf mpi_demo_02\n",
    "\n",
    "mpicc -o mpi_demo_02 mpi_demo_02.c\n",
    "\n",
    "mpirun -n 2 mpi_demo_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question\n",
    "\n",
    "What would happen if we run on only one processor? Or if we run on more than two processors?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo2\"></a>\n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "## Pass scalar data between processors\n",
    "\n",
    "<hr style=\"border:2px solid black\"></hr>\n",
    "\n",
    "In this example, we pass a scalar value `data` from processor 0 to each of the other ranks.  Rank 0 sends each rank an integer equal to its rank.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mpi_demo_03.c\n",
    "\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>    /* For IO */\n",
    "\n",
    "void main(int argc, char** argv)\n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    \n",
    "    int nprocs;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n",
    "\n",
    "    /* Hardwire length of array */\n",
    "    int tag = 0;\n",
    "    int data;\n",
    "    if (rank == 0)\n",
    "    {\n",
    "        for(int p = 1; p < nprocs; p++)\n",
    "        {\n",
    "            int dest = p;\n",
    "            int data = p;\n",
    "            MPI_Send(&data,1,MPI_DOUBLE,dest,tag,MPI_COMM_WORLD);\n",
    "        }\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        int source = 0;        \n",
    "        MPI_Recv(&data,1,MPI_DOUBLE,source,tag,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n",
    "    }\n",
    "    printf(\"Rank %d : (%d)\\n\",rank,data);\n",
    "        \n",
    "    MPI_Finalize();\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf mpi_demo_03\n",
    "\n",
    "mpicc -o mpi_demo_03 mpi_demo_03.c\n",
    "mpirun -n 4 mpi_demo_03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"demo3\"></a>\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "## Demo 3 - Pass an array between processors \n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "Rank 0 allocates an array of length 64, and initializes the array with integers $0,1,2,...64$.  Then rank 0 passes blocks of length $N/nprocs$ to the other ranks.  The program then reports the starting and ending values for the local arrays received by that rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mpi_demo_04.c\n",
    "\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>    /* For IO */\n",
    "#include <stdlib.h>   /* For malloc */\n",
    "\n",
    "void main(int argc, char** argv)\n",
    "{\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    int rank, nprocs;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &nprocs);\n",
    "\n",
    "    /* Hardwire length of array */\n",
    "    int N = 64;\n",
    "    int Nlocal = N/nprocs;\n",
    "\n",
    "    double *x;\n",
    "    int tag = 0;\n",
    "    if (rank == 0)\n",
    "    {\n",
    "        /* Allocate and initialize a big array for all data */\n",
    "        x = malloc((N+1)*sizeof(double));\n",
    "        for(int i = 0; i < N+1; i++)\n",
    "        {\n",
    "            x[i] = i;\n",
    "        }\n",
    "        for(int p = 1; p < nprocs; p++)\n",
    "        {\n",
    "            int dest = p;\n",
    "            MPI_Send(&x[p*Nlocal],Nlocal+1,MPI_DOUBLE,dest,tag,MPI_COMM_WORLD);\n",
    "        }\n",
    "    }\n",
    "    else\n",
    "    {\n",
    "        int source = 0;\n",
    "        x = malloc((Nlocal+1)*sizeof(double));\n",
    "        MPI_Recv(x,Nlocal+1,MPI_DOUBLE,source,tag,MPI_COMM_WORLD,MPI_STATUS_IGNORE);\n",
    "    }\n",
    "    printf(\"Rank %d : (%2.0f,...,%2.0f)\\n\",rank,x[0],x[Nlocal]);\n",
    "        \n",
    "    free(x);\n",
    "    \n",
    "    MPI_Finalize();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "rm -rf mpi_demo_04\n",
    "\n",
    "mpicc -o mpi_demo_04 mpi_demo_04.c\n",
    "mpirun -n 4 mpi_demo_04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
