{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510083b5",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral\"/>\n",
    "\n",
    "## Multiprocessing in Python\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"/>\n",
    "\n",
    "\n",
    "The Multiprocessing (MP) module can be used to launch OS processes and direct each process to carry out tasks.  The MP module is available as part of the standard Python package and can be imported directly without any additional installation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28bcae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adbd8c",
   "metadata": {},
   "source": [
    "#### How many cores? \n",
    "\n",
    "A very basic task is to use multiprocessing to how many CPU cores we have access to. \n",
    "\n",
    "*In what follows, we will refer to the multiprocessing package using `mp`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702054b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nprocs = mp.cpu_count()\n",
    "print(f\"Number of processors available : {nprocs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1b1d3",
   "metadata": {},
   "source": [
    "### Launching a Process\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    "\n",
    "We can launch an operating system process with the following steps: \n",
    "\n",
    "* Create an *instance* of a class `mp.Process`, \n",
    "\n",
    "     * We pass a *target* argument to indicate what we want the process to do.   In Python, this \"target\" is a Python function.\n",
    "     \n",
    "           def task():\n",
    "               # do something\n",
    "               pass\n",
    "                    \n",
    "           job = mp.Process(target=task)\n",
    "\n",
    "\n",
    "* Start the process using the class method `mp.Process.start()`\n",
    "\n",
    "      job.start()\n",
    "\n",
    "* To wait for the job to complete using the method `mp.Process.join()`\n",
    "\n",
    "      job.join()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbb2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a Process.  The process should run the function \"sayhello\"\n",
    "\n",
    "def sayhello():\n",
    "    print(\"Hello!\")\n",
    "    \n",
    "p1 = mp.Process(target=sayhello)\n",
    "\n",
    "print(\"All done - Good bye!\")     # Final statement in code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be40be",
   "metadata": {},
   "source": [
    "We see that the process didn't actually do anything, because we did not start it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c934b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a Process.  The process should run the function \"sayhello\"\n",
    "\n",
    "def sayhello():\n",
    "    print(\"Hello!\")\n",
    "    \n",
    "p1 = mp.Process(target=sayhello)\n",
    "\n",
    "p1.start()\n",
    "\n",
    "print(\"All done - Good bye!\")     # Final statement in code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad4ba5a",
   "metadata": {},
   "source": [
    "We successfully created the process, started it and the task (print\"Hello!\") was completed.  However, we got the \"Good bye\" message before the hello message.  The reason for this is that the \"start\" process is **non-blocking**.  \n",
    "\n",
    "* A **non-blocking** process does not wait for the task to complete before continuing with the code that launched the process.  \n",
    "\n",
    "To get the code to wait for the task to complete, we must include a call to a `.join()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9fa336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of a Process.  The process should run the function \"sayhello\"\n",
    "\n",
    "def sayhello():\n",
    "    print(\"Hello!\")\n",
    "    \n",
    "p1 = mp.Process(target=sayhello)\n",
    "\n",
    "p1.start()  # Launch process and return\n",
    "p1.join()   # Wait for the process to finish (or \"rejoin\" the process that launched it)\n",
    "\n",
    "print(\"All done - Good bye!\")     # Final statement in code cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7e47d",
   "metadata": {},
   "source": [
    "### Process information\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    "\n",
    "We can obtain some basic information on the processes that we launch.  The \"current process\" can be obtained from the module method `mp.current_process()'\n",
    "\n",
    "* The name of the process (as given by the MP module).  This name is user-configurable. \n",
    "\n",
    "      mp.current_process().name    # A string\n",
    "\n",
    "* The process identifier (PID)\n",
    "\n",
    "      mp.current_process().pid      # an integer\n",
    "      \n",
    "  The process ID matches the value you will see in a MacOS Activity Monitor (look for processes named `pythonX.X`, where `X.X` is the version of Python you are running.       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3100a98a",
   "metadata": {},
   "source": [
    "The process that is running this notebook can be obtained directly with the `.current_process()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a9b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mp.current_process().name)\n",
    "pid = mp.current_process().pid\n",
    "print(pid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c22220",
   "metadata": {},
   "source": [
    "This process number corresponds to a number identified by the operating system. For example, running the `ps` command at the command line identifies this process and tells us the command that started it. \n",
    "\n",
    "      (bash) % ps -p <PID>\n",
    "      \n",
    "where `PID` is the process indentified above.   The output looks something like this. \n",
    "\n",
    "    (base) (bash) ~ % ps -p 45603\n",
    "    PID TTY           TIME CMD\n",
    "    45603 ??         0:00.60 /usr/local/anaconda3/bin/python -m ipykernel_launcher -f /Users/calhoun/Library/Jupyter/runtime/kernel-d4f4fe53-c019-4fe9-ab6f-58b27d23d68a.json\n",
    "\n",
    "**Note:** The following may not work on all systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486098dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# The folowing\n",
    "cmd_args = ['ps', '-p', str(pid)]\n",
    "ps_out = subprocess.run(cmd_args,capture_output=True,text=True)\n",
    "print(ps_out.stdout,end='')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f630bf",
   "metadata": {},
   "source": [
    "Each process that we launch will also have a process name and identifier.   We can print thse from inside our task function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sayhello():\n",
    "    pname = mp.current_process().name\n",
    "    pid = mp.current_process().pid\n",
    "    print(f\"Hello from {pname} (PID: {pid})\")\n",
    "    \n",
    "p1 = mp.Process(target=sayhello)\n",
    "p1.start()\n",
    "\n",
    "# Wait for job to finish\n",
    "p1.join()\n",
    "\n",
    "print(\"All done - Good Bye.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22174d6a",
   "metadata": {},
   "source": [
    "### Running multiple processes\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    "\n",
    "We can easily launch multiple processes, each running an instance of our task.  We will configure the process name used by the MP module. \n",
    "\n",
    "The typical strategy to use when launching multiple jobs is to use a loop to create and start each job.  Then, in a second loop, we wait for each job to join the main processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2969aed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from 'My Process 0'\n",
      "Hello from 'My Process 2'\n",
      "Hello from 'My Process 1'\n",
      "Hello from 'My Process 3'\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "All done \n"
     ]
    }
   ],
   "source": [
    "def sayhello():\n",
    "    pname = mp.current_process().name\n",
    "    print(f\"Hello from {pname}\\n\")\n",
    " \n",
    "njobs = 4\n",
    "jobs = []\n",
    "for i in range(njobs):\n",
    "    p = mp.Process(target=sayhello,name=f\"'My Process {i}'\")\n",
    "    jobs.append(p)   # List of jobs\n",
    "    \n",
    "for p in jobs:\n",
    "    p.start()\n",
    "\n",
    "for j in jobs:\n",
    "    j.join()     # Wait for each job to join \n",
    "        \n",
    "print(\"All done \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459f4ab",
   "metadata": {},
   "source": [
    "Since the processes are not-blocking, the order in which each process starts is not necessarily the same as the order in which they are launched.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d85a2",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "## Timing multiple jobs\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "The processes we launched above are all running independently. As soon as we start a job, the start method returns to the parent process and we are able to create and launch a second job.  \n",
    "\n",
    "To see that these jobs are running simultaneously, we add some work to the job. A common way to create \"work\" is to have our task sleep for a specified amount of time.  The `.sleep(t)` function is part of the `time` module.  A call to the sleep function with argument `t`  will cause the function to wait for `t` seconds before returning to the calling program or process. \n",
    "\n",
    "Run the cell below and count slowly to 10 to see that the cell takes about 10 seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30773ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print(\"Sleeping ...\")\n",
    "time.sleep(10)\n",
    "print(\"Awake!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01aee7",
   "metadata": {},
   "source": [
    "We will put this sleep timer in our process and launch 4 jobs. If the jobs are all runnign simultaneously, we expect the code below to finish in 5 seconds.  \n",
    "\n",
    "To time the cost of the Python code in the cell, we will use the magic command `%%timeit`.  We will learn more about `timeit` later.  \n",
    "\n",
    "To see cleaner timing results, we remove the print statements from our task function `naptime`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5550a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "\n",
    "import time \n",
    "\n",
    "def naptime():\n",
    "    time.sleep(5)  \n",
    "\n",
    "njobs = 4\n",
    "jobs = []\n",
    "for i in range(njobs):\n",
    "    p = mp.Process(target=naptime,name=f\"Job {i}\")\n",
    "    jobs.append(p)   # List of jobs\n",
    "\n",
    "for p in jobs:\n",
    "    p.start()\n",
    "    \n",
    "for p in jobs:\n",
    "    p.join()     # Wait for each job to join \n",
    "        \n",
    "print(\"All done \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df9c26",
   "metadata": {},
   "source": [
    "We see that the jobs launched above all \"nap\" for 5 seconds simultaneously and the total cost of the function is roughly five seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf04b8b",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:2px; border-color:black\"></hr>\n",
    "\n",
    "Although our sleep timer process is a trivial example, we can already use data from this example to introduce deep concepts in parallel computing.  These are \n",
    "\n",
    "* **Latency**.  The cost of operating system overhead in lauching multiple processes. \n",
    "\n",
    "* **Weak scaling**.  The effect of system overhead on a given simulation. \n",
    "\n",
    "* **Efficiency**.  The efficiency with which a given simulation can use available compute resources. \n",
    "\n",
    "Finally, as **performance model** is a mathematical model that we can use predict the performance of a given simulation in the presence of latency and other factors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75849fcf",
   "metadata": {},
   "source": [
    "### Latency\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    "\n",
    "We can experiment with increasing the number of processses we launch to see if the total run time remains independent of the number of processes.  \n",
    "\n",
    "To collect data on this, we run the above for $N = 1,2,4,8,16,\\dots, 2048$ jobs.  To get good comparison data, we run the sleep timer for 2.5 seconds, 5 seconds and 10 seconds.  \n",
    "\n",
    "#### Question\n",
    "\n",
    "Does the total time remain independent of the number of processes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee586b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for 2.5 second sleep time\n",
    "T_data_2 = [2.53, 2.53, 2.54, 2.56, 2.61, 2.67, 2.81, 3.18, 3.91, 6.47, 11.1, 20.4]\n",
    "\n",
    "# Data for 5 second sleep time\n",
    "T_data_5 = [5.02, 5.03, 5.03, 5.05, 5.08, 5.17, 5.28, 5.57, 6.28, 7.91, 13.3, 23.3]\n",
    "\n",
    "# Data for 10 second sleep time\n",
    "T_data_10 = [10.0, 10.0, 10.0, 10.1, 10.1, 10.2, 10.3, 10.6, 11.4, 13.3, 20.6, 35.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2896f431",
   "metadata": {},
   "source": [
    "We plot the data using Numpy and Matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a60a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib.pyplot import *\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(1)\n",
    "clf()\n",
    "\n",
    "\n",
    "# Convert the data to Numpy arrays;  select first M entries (for visualization purposes)\n",
    "M = 12\n",
    "T2 = array(T_data_2)[:M]\n",
    "T5 = array(T_data_5)[:M]     # don't plot all of the data\n",
    "T10 = array(T_data_10)[:M]   \n",
    "\n",
    "# Vector of number of processes\n",
    "N = 2**arange(M)\n",
    "\n",
    "semilogx(N,T2,'g.-',ms=10,label='2.5 second sleep time')\n",
    "semilogx(N,T5,'r.-',ms=10,label='5 second sleep time')\n",
    "semilogx(N,T10,'b.-',ms=10,label='10 second sleep time')\n",
    "\n",
    "# Make nice tick marks\n",
    "pstr = ([f'{n}' for n in N])\n",
    "xticks(N,pstr)\n",
    "yticks(arange(0,36,5))\n",
    "\n",
    "xlabel('Number of processes launched')\n",
    "ylabel('Total time (s)')\n",
    "title('Total run times launching N processes')\n",
    "\n",
    "legend()\n",
    "\n",
    "grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fc084",
   "metadata": {},
   "source": [
    "We see that for each run, the timing results remain flat up until about 32 processors, where is starts to creep up.    \n",
    "\n",
    "Below, we subtract the sleep time from the total run time to get the cost of the overhead.  This \"overhead\" roughly corresponds to what is called *latency* in high performance computing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec109e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(2)\n",
    "clf()\n",
    "\n",
    "# Compute latency for each runs with sleep times 2.5s, 5s and 10s. \n",
    "L2 = T2 - 2.5\n",
    "L5 = T5 - 5\n",
    "L10 = T10 - 10\n",
    "\n",
    "# Array of N values : 1,2,4,8,16,32,...,2048\n",
    "N = 2**arange(len(L5))\n",
    "\n",
    "loglog(N,L2,'g.-',ms=10,label=\"2.5 second sleep time\")\n",
    "loglog(N,L5,'r.-',ms=10,label=\"5 second sleep time\")\n",
    "loglog(N,L10,'b.-',ms=10,label=\"10 second sleep time\")\n",
    "\n",
    "xlabel('Number of processes')\n",
    "ylabel('Latency (s)')\n",
    "title('Latency')\n",
    "\n",
    "# Make nice tick marks\n",
    "pstr = ([f'{n}' for n in N])\n",
    "xticks(N,pstr)\n",
    "\n",
    "ytick = logspace(log10(0.02),log10(25),10)\n",
    "pstr = ([f'{y:.1f}' for y in ytick])\n",
    "yticks(ytick,pstr)\n",
    "\n",
    "\n",
    "grid()\n",
    "\n",
    "legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f2698e",
   "metadata": {},
   "source": [
    "From the above plot, we see that the fixed costs associated with launching $N$ jobs is roughly independent of the actual sleep time.  This suggests that these fixed costs (or *latency*) are associated with the operating system launching, starting and managing the $N$ jobs, rather than something to do with the actual \"job\" (our sleep timer) that we are running. \n",
    "\n",
    "The three latency curves in the latency plot appear to be straight lines in loglog space.  This suggests a relationship between latency $L$  and number of processes $N$\n",
    "given by \n",
    "\n",
    "\\begin{equation}\n",
    "\\log(L) = p \\log(N) + \\overline{C}\n",
    "\\end{equation}\n",
    "\n",
    "for some constant $\\overline{C}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde46b78",
   "metadata": {},
   "source": [
    "Using our data from above, we can estimate values $p$ and $\\overline{C}$ using linear regression on the log data.  \n",
    "\n",
    "Below, we fit the data from the 10 second sleep timing to a line to get slope $p$ and constant $\\overline{C}$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff636a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute a best-fit line. \n",
    "pC = polyfit(log(N[3:]),log(L10[3:]),1)   # Skip values where L = 0. \n",
    "\n",
    "p = pC[0]  # power p\n",
    "Cbar = pC[1]  # Constant C\n",
    "print(f\"Power p is approx. {p:.2f}\")\n",
    "print(f\"Constant C is approx. {Cbar:.2e} (s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61327f31",
   "metadata": {},
   "source": [
    "The linear relationship between the log data can be written equivalent as\n",
    "\n",
    "\\begin{equation}\n",
    "L \\approx C N^p, \\quad C = e^{\\overline{C}}\n",
    "\\end{equation}\n",
    "\n",
    "The value of $p$ is approximately 1 and so the latency is *proportional* to the number of processes launched. \n",
    "\n",
    "\\begin{equation}\n",
    "L \\sim N.\n",
    "\\end{equation}\n",
    "\n",
    "The constant of propotionality $C = e^{\\overline{C}}$ is typically very small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f58927",
   "metadata": {},
   "source": [
    "#### A performance model\n",
    "\n",
    "Based on the above, we can create a *performance model* describing the time $T$ it takes\n",
    "to run our $N$ \"sleep\" tasks as a function of the number of processes launched.  This model can be written as\n",
    "\n",
    "\\begin{equation}\n",
    "T = T_s + \\alpha N\n",
    "\\end{equation}\n",
    "\n",
    "where $T_s$ is the sleep time, and $\\alpha$ is the latency parameter that will vary from system to system.  For the data above, this parameter is $\\alpha = C \\sim \\mathcal O(10^{-3})$ ms.  \n",
    "\n",
    "To test this model, we can compare our model values to actual values we found above.  We compare our performance model against actual timing results for $N=256$ processes.\n",
    "\n",
    "Below, we provide three values\n",
    "\n",
    "* **Ideal time** The time a \"perfect\" code (without latency) would take. For this problem, this is the sleep time. \n",
    "\n",
    "* **Actual time** Timing results computed using `timeit` in code cells above. \n",
    "\n",
    "* **Performance Model** Time predicted by our performance model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ad486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A performance model\n",
    "N0 = 256\n",
    "I = 8\n",
    "assert N0 == N[I], \"Indices are not consistent\"\n",
    "alpha = C\n",
    "L = alpha*N0\n",
    "\n",
    "print(f\"Performance model for launching {N0} processes\\n\")\n",
    "\n",
    "print(\"{:>8s} {:>12s} {:>12s}\".format(\"Ideal time\",\"Actual time\", \"Perf. Model\"))\n",
    "print(\"{:s}\".format('-'*38))\n",
    "\n",
    "fstr = \"{:8.2f} {:12.2f} {:12.2f}\".format\n",
    "print(fstr(2.5, T2[I], 2.5 + L))   # index 7 corresponds to N=128\n",
    "print(fstr(5,T5[I], 5+L))\n",
    "print(fstr(10,T10[I],10+L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a368f98",
   "metadata": {},
   "source": [
    "The estimated value from the latency model is only slightly larger than the actual timing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c853ad2",
   "metadata": {},
   "source": [
    "### Weak scaling\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    "\n",
    "In the above example, each process had the same amount of work to do, regardless of how many processes we launch.  The first timing plot is an example of a \"weak scaling\" plot.  \n",
    "\n",
    "* *Weak scaling*  The work per processor is held fixed while increasing the number of processes. \n",
    "\n",
    "An ideal weak scaling plot would be a horizontal line.  We can qualitatively describe the weak scaling of a system by observing how far the actual curve deviates from  this ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff91f0f",
   "metadata": {},
   "source": [
    "### Efficiency\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:black\"></hr>\n",
    " \n",
    "\n",
    "A related concept is the *efficiency* of a simulation and addresses the question as to how efficiently jobs a are able to use the computational resources available.  Efficiency on $N$ processors is measured as \n",
    "\n",
    "\\begin{equation}\n",
    "E = \\frac{\\mbox{Ideal time}}{\\mbox{Actual time}}\n",
    "\\end{equation}\n",
    "\n",
    "A simulation with perfect weak scaling will be 100\\% efficient.  A job in which overhead (or latency) begins to dominate will have lower efficiency.  \n",
    "\n",
    "Below, we show an efficiency plots for each of the three sleep simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ad1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(3)\n",
    "clf()\n",
    "\n",
    "axhline(y=100,linewidth=2,color='black')\n",
    "axhline(y=80,linewidth=2,color='black')\n",
    "\n",
    "\n",
    "semilogx(N,2.5/T2*100,'g.-',ms=10,label=\"2.5 second sleep timer\")\n",
    "semilogx(N,5/T5*100,'r.-',ms=10,label=\"5 second sleep timer\")\n",
    "semilogx(N,10/T10*100,'b.-',ms=10,label=\"10 second sleep timer\")\n",
    "\n",
    "# Ts = 10\n",
    "# semilogx(N,(1 - alpha/Ts*N)*100,'k:',linewidth=2,label=\"Predicted (10s timer)\")\n",
    "\n",
    "\n",
    "xlabel('Number of processes')\n",
    "ylabel('Efficiency (%)')\n",
    "title('Efficiency')\n",
    "\n",
    "# Make nice tick marks\n",
    "pstr = ([f'{n}' for n in N])\n",
    "xticks(N,pstr)\n",
    "\n",
    "ytick = linspace(0,100,6)\n",
    "pstr = (['{:.0f} %'.format(y) for y in ytick])\n",
    "yticks(ytick,pstr)\n",
    "\n",
    "ylim([0,100])\n",
    "\n",
    "\n",
    "legend()\n",
    "\n",
    "grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac61e7d",
   "metadata": {},
   "source": [
    "Efficiency drops off as the number of processes is increased.  Here, we see good efficiency (e.g. over 80%) up to about 128 processes for the 5 second sleep job and past 256 processes for the 10 second sleep job.  As is typical behavior for multiple jobs, efficiency drops off with number of processes and longer jobs remain more efficient for larger number of processes, since they are better able to amortize the latency costs.\n",
    "\n",
    "The reason the effiency drops off is evident in our performance model.  Assuming that $\\alpha N \\ll 1$, we can approximate the efficiency $E$ using a Taylor series expansion to get \n",
    "\n",
    "\\begin{equation}\n",
    "E = \\frac{T_s}{T_s + \\alpha N} = \\frac{1}{1 + \\alpha\\frac{N}{T_s}} \\approx \n",
    "1 - \\frac{\\alpha N}{T_s} < 1\n",
    "\\end{equation}\n",
    "\n",
    "This also shows why larger $T_s$ (our sleep time) will lead to better efficiency, for a fixed $N$.  \n",
    "\n",
    "For larger $N$, we will have $\\alpha N \\gg 1$ and we can approximate the efficiency model as \n",
    "\n",
    "\\begin{equation}\n",
    "E = \\frac{T_s}{T_s + \\alpha N} \\sim \\frac{T_s}{\\alpha N} \\rightarrow 0. \n",
    "\\end{equation}\n",
    "\n",
    "As $N$ increases, the latency dominates the simulation time, and efficiency goes to zero. \n",
    "\n",
    "The predicted efficiency, and the two different regimes, depending on the size of $\\alpha N$ aer shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(4)\n",
    "clf()\n",
    "\n",
    "axhline(y=100,linewidth=2,color='black')\n",
    "axhline(y=80,linewidth=2,color='black')\n",
    "\n",
    "N = 2**arange(len(T10))\n",
    "semilogx(N,10/T10*100,'b.-',ms=10,label=\"10 second sleep timer\")\n",
    "\n",
    "def Eff(N,Ts,alpha):\n",
    "    return 100/(1 + alpha*N/Ts)\n",
    "\n",
    "\n",
    "Ts = 10\n",
    "\n",
    "Ns = logspace(0,log10(2**18),100)\n",
    "semilogx(Ns,Eff(Ns,Ts,alpha),'k-',lw=1.5,label=\"Efficiency model\")\n",
    "\n",
    "semilogx(Ns,(1 - alpha*Ns/Ts)*100,'k:',linewidth=1.5,label=r\"$\\alpha N/T_s \\ll 1$\")\n",
    "semilogx(Ns,100*Ts/(alpha*Ns),'k--',linewidth=1.5,label=r\"$\\alpha N/T_s \\gg 1$\")\n",
    "\n",
    "xlabel('Number of processes')\n",
    "ylabel('Efficiency (%)')\n",
    "title('Efficiency (Model)')\n",
    "\n",
    "# Make nice tick marks\n",
    "Nv = 2**arange(18)\n",
    "pstr = ([f'{n}' for n in Nv[::2]])\n",
    "xticks(Nv[::2],pstr)\n",
    "\n",
    "ytick = linspace(0,100,6)\n",
    "pstr = (['{:.0f} %'.format(y) for y in ytick])\n",
    "yticks(ytick,pstr)\n",
    "\n",
    "ylim([-10,110])\n",
    "\n",
    "\n",
    "legend()\n",
    "\n",
    "grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb41dc1",
   "metadata": {},
   "source": [
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "## Links\n",
    "\n",
    "<hr style=\"border-width:4px; border-color:coral\"></hr>\n",
    "\n",
    "Here is link that goes into more detail on the Multiprocessing module. \n",
    "\n",
    "[SuperfastPthon](https://superfastpython.com/multiprocessing-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cae1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
